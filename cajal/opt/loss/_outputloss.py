"""
Losses that compare the predicted pattern of activity as a result of some
stimulation configuration in a compound fibre model to the desired pattern
of activity.
"""

from abc import ABC, abstractmethod

import numpy as np


_MACHEPS = np.finfo(np.float64).eps


class OutputLoss(ABC):
    """Abstract base class for output losses (losses that operate
    on tuples of return variables generated by your model).

    In order to subclass OutputLoss:

        Define a class:
        class MyLoss(OutputLoss):
            def __init__(self, param1, param2 ...):
                super(MyLoss, self).__init__()
                self.param1 = param1
                self.param2 = param2
                ...

            def loss(self, *outputs):
                ```
                Define logic to calculate loss from outputs,
                and parameters defined in __init__ and return
                loss.
                ```

    OutputLoss operates on return variables in the order they
    are returned by the relevant function / method.

    The new loss can then be used with the core DifferentialEvolution
    classes."""

    loss_type = "output"
    required = ["output"]

    def __init__(self):
        self._scale = 1

    @abstractmethod
    def loss(self, *args):
        """Calculate the loss between target and predicted."""

    def __call__(self, *outputs):
        return self._scale * self.loss(*outputs)

    def __rmul__(self, val):
        self.__scale = val
        return self


class PredictionLoss(OutputLoss):
    def __init__(self, target):
        super(PredictionLoss, self).__init__()
        self.target = target

    @abstractmethod
    def loss(self, target, predicted):
        """Calculate the loss between target and predicted."""

    def __call__(self, *outputs):
        return self._scale * self.loss(target=self.target, predicted=outputs[0])


class WeightedDifference(PredictionLoss):
    """Custom loss metric that takes into consideration total proportion of
    correctly activated axons and total proportion of incorrectly activated
    axons."""

    def __init__(self, target, smooth=1):
        super(WeightedDifference, self).__init__(target)
        self.smooth = smooth

    def loss(self, target, predicted):
        intersection = np.sum(np.abs(target * predicted))
        intersection_ = intersection / np.sum(target)
        sum_ = np.sum(np.abs(target) + np.abs(predicted))
        scale_sum = (sum_ - intersection - np.sum(np.abs(target))) / (
            target.shape[0] - np.sum(np.abs(target)) + _MACHEPS
        )

        loss = (
            ((1 - intersection_) + self.smooth) * (scale_sum + self.smooth)
        ) - self.smooth**2

        return loss


class Hamming(PredictionLoss):
    """Hamming Distance"""

    def loss(self, target, predicted):
        return np.count_nonzero(target != predicted)


class SMD(Hamming):
    """Simple Matching Distance"""

    def __init__(self, target):
        super(SMD, self).__init__(target)

    def loss(self, target, predicted):
        return super().loss(target, predicted) / target.shape[0]


class Jaccard(PredictionLoss):
    """Jaccard Distance"""

    def loss(self, target, predicted):
        x = np.asarray(target).astype(np.bool)
        y = np.asarray(predicted).astype(np.bool)

        if x.size != y.size:
            raise ValueError(
                "Shape mismatch: target and prediction " "must have the same shape."
            )

        # Compute Dice coefficient
        intersection = np.logical_and(x, y)
        union = np.logical_or(x, y)

        return 1 - (intersection.sum() / (union.sum() + _MACHEPS))


class Dice(PredictionLoss):
    """Dice dissimilarity"""

    def loss(self, target, predicted):
        x = np.asarray(target).astype(np.bool)
        y = np.asarray(predicted).astype(np.bool)

        if x.shape != y.shape:
            raise ValueError(
                "Shape mismatch: target and prediction " "must have the same shape."
            )

        # Compute Dice coefficient
        intersection = np.logical_and(x, y)

        return 1 - (2.0 * intersection.sum() / (x.sum() + y.sum() + _MACHEPS))


class OnTarget(PredictionLoss):
    """Loss based on the proportion of target axons activated."""

    def loss(self, target, predicted):
        correct = np.logical_and(target, predicted).sum()
        den = np.sum(target) + _MACHEPS

        return 1 - correct / den


class OffTarget(PredictionLoss):
    """Loss based on the proportion of off-target axons activated."""

    def loss(self, target, predicted):
        incorrect = np.logical_and(target == 0, predicted == 1).sum()
        den = np.size(target) - np.sum(target) + _MACHEPS

        return incorrect / den


class WeightedBinaryCrossEntropy(PredictionLoss):
    def __init__(self, target, weights):
        super(WeightedBinaryCrossEntropy, self).__init__(target)
        self.weights = weights

    def loss(self, target, predicted):
        target = np.asarray(target)
        predicted = np.asarray(predicted).flatten()
        term_0 = (1 - target) * np.log(1 - predicted + _MACHEPS)
        term_1 = target * np.log(predicted + _MACHEPS)
        return -np.average((term_0 + term_1), axis=0, weights=self.weights)
